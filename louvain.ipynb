{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "louvain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jin-K-Yang/Clustering-by-Louvain-Algorithm/blob/main/louvain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow1H16iJB1cW",
        "outputId": "6f2d4ab2-a144-4bad-dc37-1216c63c49fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbeSnMLra_Wo"
      },
      "source": [
        "# 定義函示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPVErasgmPzB"
      },
      "source": [
        "import community as community_louvain\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "from glob import glob\n",
        "\n",
        "def create_graph(filename):\n",
        "  # load one excel file\n",
        "  df = pd.read_excel(filename, usecols=['會員編號', '部門編號'], converters={'部門編號':str})\n",
        "  df = df.dropna(how='any',axis=0) \n",
        "\n",
        "  # convert into two array which represent customer and product\n",
        "  array = df.to_numpy()\n",
        "  split_array = np.hsplit(array, 2)\n",
        "  customer = split_array[0]\n",
        "  product = split_array[1]\n",
        "\n",
        "  # construct bipartite graph\n",
        "  G = nx.Graph()\n",
        "  for i in range(len(product)):\n",
        "      # zero padding\n",
        "      product[i][0] = product[i][0].zfill(5)\n",
        "\n",
        "      # add nodes\n",
        "      G.add_nodes_from(product[i], bipartite = 0)\n",
        "      G.add_nodes_from(customer[i], bipartite = 1)\n",
        "      \n",
        "      # add edges\n",
        "      if G.has_edge(product[i][0], customer[i][0]):\n",
        "          G[product[i][0]][customer[i][0]]['weight'] += 1\n",
        "      else:\n",
        "          G.add_edge(product[i][0], customer[i][0], weight = 1)\n",
        "  return G\n",
        "\n",
        "# folder version\n",
        "def create_graph_folder(filename):\n",
        "  # load multiple excel file\n",
        "  files = glob(filename)\n",
        "  df = pd.concat([pd.read_excel(f, usecols=['會員編號', '部門編號'], converters={'部門編號':str}) for f in files])\n",
        "  df = df.dropna(how='any',axis=0) \n",
        "\n",
        "  # convert into two array which represent customer and product\n",
        "  array = df.to_numpy()\n",
        "  split_array = np.hsplit(array, 2)\n",
        "  customer = split_array[0]\n",
        "  product = split_array[1]\n",
        "\n",
        "  # construct bipartite graph\n",
        "  G = nx.Graph()\n",
        "  for i in range(len(product)):\n",
        "      # zero padding\n",
        "      product[i][0] = product[i][0].zfill(5)\n",
        "\n",
        "      # add nodes\n",
        "      G.add_nodes_from(product[i], bipartite = 0)\n",
        "      G.add_nodes_from(customer[i], bipartite = 1)\n",
        "      \n",
        "      # add edges\n",
        "      if G.has_edge(product[i][0], customer[i][0]):\n",
        "          G[product[i][0]][customer[i][0]]['weight'] += 1\n",
        "      else:\n",
        "          G.add_edge(product[i][0], customer[i][0], weight = 1)\n",
        "  return G\n",
        "\n",
        "def louvain(G):\n",
        "  # show the total number of nodes and edges\n",
        "  # print(G.number_of_nodes())\n",
        "  # print(G.number_of_edges())\n",
        "\n",
        "  # compute the best partition\n",
        "  partition = community_louvain.best_partition(G)\n",
        "  # print(partition)\n",
        "\n",
        "  # classify the result\n",
        "  community = {}\n",
        "  for key, value in set(partition.items()):\n",
        "      if key[0].isalpha():\n",
        "          community.setdefault(value, {}).setdefault('customer', []).append(key)\n",
        "      else:\n",
        "          community.setdefault(value, {}).setdefault('product', []).append(key)\n",
        "\n",
        "  # calculate the sum of edges of clusters\n",
        "  for i in range(len(community)):\n",
        "    SG = G.subgraph(community[i]['product'] + community[i]['customer'])\n",
        "    community[i]['edges_sum'] = SG.number_of_edges()\n",
        "\n",
        "  return community\n",
        "  \"\"\"\n",
        "  total_name=''\n",
        "  for i in range(len(community)):\n",
        "    print(i)\n",
        "    for j in community[i]['product']:\n",
        "      total_name += num_to_product(j)\n",
        "      total_name += ' , '\n",
        "    print(total_name)\n",
        "    total_name=''\n",
        "  \"\"\"\n",
        "\n",
        "# benefit-cost analysis\n",
        "def benefit_cost(community):\n",
        "  benefit = {\n",
        "      'Customer_Count':[],\n",
        "      'Product_Count':[],\n",
        "      'Cost':[],\n",
        "      'Benefit':[],\n",
        "      'Ratio':[],\n",
        "  }\n",
        "\n",
        "  total = {\n",
        "      'Customer_Count':0,\n",
        "      'Product_Count':0,\n",
        "      'Cost':0,\n",
        "      'Benefit':0,\n",
        "      'Ratio':0,\n",
        "  }\n",
        "\n",
        "  for i in range(len(community)):\n",
        "      benefit['Customer_Count'].append(len(community[i]['customer']))\n",
        "      benefit['Product_Count'].append(len(community[i]['product']))\n",
        "      benefit['Cost'].append(len(community[i]['customer']) * len(community[i]['product']))\n",
        "      benefit['Benefit'].append(community[i]['edges_sum'])\n",
        "      benefit['Ratio'].append(community[i]['edges_sum'] / (len(community[i]['customer']) * len(community[i]['product'])))\n",
        "\n",
        "      total['Customer_Count'] += len(community[i]['customer'])\n",
        "      total['Product_Count'] += len(community[i]['product'])\n",
        "      total['Cost'] += len(community[i]['customer']) * len(community[i]['product'])\n",
        "      total['Benefit'] += community[i]['edges_sum']\n",
        "\n",
        "  total['Ratio'] = total['Benefit'] / total['Cost']\n",
        "\n",
        "  df_total = pd.DataFrame(total, index=['total'])\n",
        "  df_benefit = pd.DataFrame(benefit)\n",
        "\n",
        "  result = pd.concat([df_benefit, df_total])\n",
        "  return result\n",
        "\n",
        "# map the department number and deparment name from excel file\n",
        "def map_department(file):\n",
        "  map_df = pd.read_excel(file, usecols=['部門名稱', '部門編號'], converters={'部門編號':str})\n",
        "  map_array = np.hsplit(map_df.to_numpy(), 2)\n",
        "  map = {}\n",
        "\n",
        "  for i in range(len(map_array[0])):\n",
        "    map[map_array[0][i][0].zfill(5)] = map_array[1][i][0]\n",
        "  return map\n",
        "\n",
        "# show the product name in each clusters\n",
        "def show_product(map, community):\n",
        "  temp = copy.deepcopy(community)\n",
        "  for i in range(len(temp)):\n",
        "    for j in range(len(temp[i]['product'])):\n",
        "      temp[i]['product'][j] = map[temp[i]['product'][j]]\n",
        "    print(temp[i]['product'])\n",
        "  return temp"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6PJMWhwBEuU"
      },
      "source": [
        "# 建立Excel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjLa3U0lYRGM"
      },
      "source": [
        "# write result to the excel file\n",
        "import openpyxl\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "# You can change the file address below this line\n",
        "total_result_file_name = '/content/drive/Shareddrives//louvain/test_result.xlsx'\n",
        "\n",
        "def write_clusters(file_name, sheet_name, result):\n",
        "  wb = load_workbook(filename = file_name)\n",
        "  sheet = wb[sheet_name]\n",
        "  for i in range(len(result)):\n",
        "    for j in range(len(result[i]['product'])):\n",
        "      sheet.cell(row=i+2, column=7+j).value = result[i]['product'][j]\n",
        "    # write the customer data into the excel file\n",
        "    for k in range(len(result[i]['customer'])):\n",
        "      sheet.cell(row=30, column=i+1).value = '分群' + str(i)\n",
        "      sheet.cell(row=k+31, column=i+1).value = result[i]['customer'][k]\n",
        "  wb.save(file_name)\n",
        "  print('All clusters have benn written in file.')\n",
        "\n",
        "def write_transaction(file_name, sheet_name, G, map):\n",
        "  wb = load_workbook(filename = file_name)\n",
        "  sheet = wb.create_sheet(sheet_name)\n",
        "  sheet.cell(row=1, column=1).value = '顧客'\n",
        "  sheet.cell(row=1, column=2).value = '產品'\n",
        "  sheet.cell(row=1, column=3).value = '購買次數'\n",
        "\n",
        "  for i, e in enumerate(G.edges.data(\"weight\", default=1)):\n",
        "    if e[0][0].isalpha():\n",
        "      sheet.cell(row=2+i, column=1).value = e[0]\n",
        "      sheet.cell(row=2+i, column=2).value = map[e[1]]\n",
        "    else:\n",
        "      sheet.cell(row=2+i, column=1).value = e[1]\n",
        "      sheet.cell(row=2+i, column=2).value = map[e[0]]\n",
        "    sheet.cell(row=2+i, column=3).value = e[2]\n",
        "  wb.save(file_name)\n",
        "  print('The transactions of {index} have been written in file.'.format(index=sheet_name))\n",
        "\n",
        "# with pd.ExcelWriter(total_result_file_name) as writer:  \n",
        "#   benefit_cost_2018_2021.to_excel(writer, sheet_name='3年(20180601-20210531)')\n",
        "#   benefit_cost_2016_2021.to_excel(writer, sheet_name='5年(20160601-20210531)')\n",
        "#   benefit_cost_2014_2021.to_excel(writer, sheet_name='7年(20140601-20210531)')\n",
        "\n",
        "# write_clusters(total_result_file_name, '3年(20180601-20210531)', result_2018_2021)\n",
        "# write_clusters(total_result_file_name, '5年(20160601-20210531)', result_2016_2021)\n",
        "# write_clusters(total_result_file_name, '7年(20140601-20210531)', result_2014_2021)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGgwsPqHUTix"
      },
      "source": [
        "# 分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRX-PooQDDDK",
        "outputId": "2401b967-7643-48fd-f4f3-7890dee17f62"
      },
      "source": [
        "# option argument for folder, if it is True then the function will proccess all file in input address.\n",
        "def analysis(input_file, output_file, folder = False):\n",
        "  sheet_name = 'benefit_cost'\n",
        "\n",
        "  if folder == False:\n",
        "    G = create_graph(input_file)\n",
        "  else:\n",
        "    G = create_graph_folder(input_file)\n",
        "\n",
        "  result = louvain(G)\n",
        "  benefit = benefit_cost(result)\n",
        "  with pd.ExcelWriter(output_file) as writer:  \n",
        "    benefit.to_excel(writer, sheet_name=sheet_name)\n",
        "\n",
        "  map = map_department('/content/drive/Shareddrives//louvain/department_list.xlsx')\n",
        "  map_result = show_product(map, result)\n",
        "\n",
        "  write_clusters(output_file, sheet_name, map_result)\n",
        "  for i in range(len(result)):\n",
        "    SG = G.subgraph(result[i]['product'] + result[i]['customer'])\n",
        "    write_transaction(output_file, 'Cluster {index}'.format(index=i), SG, map)\n",
        "\n",
        "analysis('/content/drive/Shareddrives//louvain/year/20160601-20210531/*.xlsx', '/content/drive/Shareddrives//louvain/result/20160601-20210531_reult.xlsx', folder=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['家飾類-毛浴枕巾', '涼被-6980以上', '食品類', '家飾類-公司自製品']\n",
            "['床包-13系列', '中式床罩-8500係列', '中式床罩-1980系列', '枕頭-其他種類', '枕頭-零碼及特價品', '中式床罩-25全套組', '中式床罩-2380系列', '中式床罩-X系列', '枕頭-化纖枕', '23系列枕套', '中式床罩-6980以上', '床罩-B卡通系列', '中式床罩-2980系列', '中式床罩-3280系列', '舖棉床包組-23系列']\n",
            "['家飾類-踏墊', '居家服飾-內褲', '家飾類-拖鞋']\n",
            "['舖棉床包組-2980系', '薄被套-2380系列', '棉被-化纖被', '薄被套-其他', '薄被套-B系列卡通', '兩用被-零碼及特價', '薄被套-2380系列', '涼被-2980系列', '床包-零碼及特價品', '涼被-4980系列', '涼被-零碼及特價品', '薄被套-CR611/65絲', '兩用被-3280系列', '涼被-23系列', '薄被套-2980系列', '襪子', '薄被套-CR201天絲', '棉被-羽絨被', '棉被-蠶絲被', '棉被-羊毛被', '兩用被-2980系列', '涼被-5380系列', '薄被套-5980系列', '家具-其他', '床包-2980系列', '薄被套-53系列', '棉被-零碼及特價品']\n",
            "['床包-X1系列', '枕頭套-X1系列', '兩用被-13系列', '床包-53系列', '枕頭套-5380系列', '床包-25系列', '中式床罩-4980系列', '枕頭套-25係列', '兩用被-53系列', '兩用被-X1系列', '床包-X2系列', '舖棉床包-25系列', '兩用被-X1系列', '2380系列床包', '中式床罩-25系列', '兩用被-2380系列', '兩用被-25系列', '保潔墊-一般']\n",
            "['家飾類-抱枕', '家具-電動床', '中式床罩零碼及特', '枕頭套-零碼及特價']\n",
            "['家具-特賣品', '枕頭-矽膠枕', '枕頭-乳膠枕', '保潔墊-機能性']\n",
            "['兩用被-CR611/65絲', '枕頭套-P801~PIMA', '枕頭套-CR611/65絲', '兩用被-P801~PIMA', '薄被套-PIMA棉', '床罩-CR611/6500絲', '床包-CR611/6500絲', '舒柔被-PIMA', '夏罩-P801~PIMA系', '床罩-P801~PIMA棉', '床包-P801~PIMA棉']\n",
            "['薄墊套-CR CL系列', '薄墊套-拉鍊床墊布', '床墊-簡易床墊', '薄墊套-65系列', '薄墊套-25系列', '薄墊套-2980系列', '枕頭套-3280系列', '枕頭套-2980系列', '薄墊套-T天絲系列']\n",
            "['毛毯-單人毯', '毛毯-雙人毯']\n",
            "['嬰兒七件式床組', '家飾類-竹蓆', '家飾類-坐墊/腰靠', '家飾類-蚊帳及睡簾', '外購涼被']\n",
            "['家具-衣櫥', '家具-書桌', '特價床包涼被組', '家具-床頭', '鋪棉床墊套', '床墊-潘柏', 'J系列床包A被組', '床墊-德泰', '床墊-其他', '家具-床底', '床墊-老K', '床墊-天妮絲', '家具-休閒椅', '自製床包A被組', '床墊-康適', '家具-床架', '床墊-喬福', '家具-鐵床', '床墊-舒達']\n",
            "['床包-CR201~天絲棉', '兩用被-C4系列', '床包-3980系列', '床包A被組', '枕頭套-3980系列', '舖棉床包-立體車花', '枕頭套-CR201天絲', '居家服飾-其他', '薄被套-C4系列', '床罩-CR201天絲棉', '中式床罩-3880系列', '空氣清淨', '涼被-針織', '床包-C4系列', '枕頭套-C4系列', '兩用被-CR201~天絲', '涼被-CR及CL系列', '兩用被-3980系列']\n",
            "['枕頭套-CR501/A53~', '兩用被-6980以上', '床包-CR501/A53~', '床罩-CR501/A53~', '床包-4980系列', '兩用被-5980系列', '枕頭套-CR301~', '薄被套-6980以上', '兩用被-4980系列', '舖棉床包-A系列', '床包-6980以上', '中式床罩-5980系列', '兩用被-CR501/A53~', '薄被套-CR501/A53~', '床包-5980系列', '枕頭套-5980系列', '兩用被-CR301~', '涼被-5980系列', '床包-CR301~']\n",
            "['床包-SR GR系列', '薄被套-T702~天絲', '床包-T702~天絲系', '夏罩-T702~天絲系', '小物', '舒柔被', '枕頭套-SR GR系列', '枕頭套-J9001~', '兩用被-SR系列', '兩用被-J9001~', '中式床罩-CR全套組', '床包-J9001~', '超輕薄被', '薄被套-SR GR 系列', '枕頭套-T702~天絲', '中式床罩-J9001~', '枕頭套-機能性/其', '兩用被-T702~天絲', '床罩-T702~天絲系', '中式床罩-SR系列']\n",
            "['涼被-25系列', '枕頭套-B系列卡通', '兩用被-外購', '毛毯-童毯', '薄墊套-外購', '棉被-睡袋', '嬰兒襪', '床墊-銘祥', '床包-B系列卡通', '兩用被-B系列卡通', '薄墊套-4380系列', '枕頭-兒童枕', '涼被-B系列卡通', '嬰兒被套', '家飾類-其他']\n",
            "['洗潔劑', '沛美', '家飾類-手工皂', '保溫杯/保鮮盒']\n",
            "All clusters have benn written in file.\n",
            "The transactions of Cluster 0 have been written in file.\n",
            "The transactions of Cluster 1 have been written in file.\n",
            "The transactions of Cluster 2 have been written in file.\n",
            "The transactions of Cluster 3 have been written in file.\n",
            "The transactions of Cluster 4 have been written in file.\n",
            "The transactions of Cluster 5 have been written in file.\n",
            "The transactions of Cluster 6 have been written in file.\n",
            "The transactions of Cluster 7 have been written in file.\n",
            "The transactions of Cluster 8 have been written in file.\n",
            "The transactions of Cluster 9 have been written in file.\n",
            "The transactions of Cluster 10 have been written in file.\n",
            "The transactions of Cluster 11 have been written in file.\n",
            "The transactions of Cluster 12 have been written in file.\n",
            "The transactions of Cluster 13 have been written in file.\n",
            "The transactions of Cluster 14 have been written in file.\n",
            "The transactions of Cluster 15 have been written in file.\n",
            "The transactions of Cluster 16 have been written in file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p0goahrC2uH"
      },
      "source": [
        "# 畫出文氏圖"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "o1xzv_AhJxZK",
        "outputId": "8c5abdd9-b6a9-4d52-8bac-8d1dd3111963"
      },
      "source": [
        "#compare each clusters' people if they are same and draw the Venn diagram to the excel file\n",
        "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
        "from matplotlib_venn import venn3, venn3_circles\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def compare_two_years(cluster_1, cluster_2):\n",
        "  count = 0\n",
        "  for i in range(len((cluster_1['customer']))):\n",
        "    for j in range(len(cluster_2['customer'])):\n",
        "      if cluster_1['customer'][i] == cluster_2['customer'][j]:\n",
        "        count += 1\n",
        "  return count\n",
        "\n",
        "def compare_three_years(cluster_1, cluster_2, cluster_3):\n",
        "  count = 0\n",
        "  for i in range(len((cluster_1['customer']))):\n",
        "    for j in range(len(cluster_2['customer'])):\n",
        "      if cluster_1['customer'][i] == cluster_2['customer'][j]:\n",
        "        for k in range(len(cluster_3['customer'])):\n",
        "          if cluster_1['customer'][i] == cluster_3['customer'][k]:\n",
        "            count += 1\n",
        "  return count\n",
        "\n",
        "def draw_Venn_diagram(cluster_1, cluster_2, cluster_3, file_name, sheetname):\n",
        "  plt.title('The number of customers who have purchased this group in 2018, 2019 and 2020')\n",
        "  venn3(subsets = (len(cluster_1['customer']), len(cluster_2['customer']), compare_two_years(cluster_1, cluster_2), len(cluster_3['customer']), compare_two_years(cluster_1, cluster_3), compare_two_years(cluster_2, cluster_3), compare_three_years(cluster_1, cluster_2, cluster_3)), set_labels = ('The number of customers who bought this group in 2018', 'The number of customers who bought this group in 2019', 'The number of customers who bought this group in 2020'))\n",
        "\n",
        "  plt.savefig(sheetname, bbox_inches='tight')\n",
        "  plt.clf()\n",
        "  wb = load_workbook(filename = file_name)\n",
        "  sheet = wb.create_sheet(sheetname)\n",
        "\n",
        "  img = openpyxl.drawing.image.Image(sheetname + '.png')\n",
        "  img.anchor = 'A1'\n",
        "  sheet.add_image(img)\n",
        "\n",
        "  wb.save(file_name)\n",
        "\n",
        "draw_Venn_diagram(result_2018[0], result_2019[5], result_2020[22], total_result_file_name, '25系列')\n",
        "draw_Venn_diagram(result_2018[10], result_2019[17], result_2020[19], total_result_file_name, '雙人毯,單人毯')\n",
        "draw_Venn_diagram(result_2018[7], result_2019[15], result_2020[12], total_result_file_name, '床墊,床頭,床架')\n",
        "draw_Venn_diagram(result_2018[14], result_2019[12], result_2020[0], total_result_file_name, '天絲')\n",
        "draw_Venn_diagram(result_2018[2], result_2019[6], result_2020[7], total_result_file_name, 'CR501,A53')\n",
        "draw_Venn_diagram(result_2018[20], result_2019[22], result_2020[3], total_result_file_name, '53系列')\n",
        "draw_Venn_diagram(result_2018[16], result_2019[7], result_2020[8], total_result_file_name, 'CR611,6500絲')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrJR9eREbJUx"
      },
      "source": [
        "# 畫圖(未完成)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qn9N4I9tOsq"
      },
      "source": [
        "# draw the graph\n",
        "pos = nx.spring_layout(G)\n",
        "\n",
        "# color the nodes according to their partition\n",
        "cmap = cm.get_cmap('viridis', max(partition.values()) + 1)\n",
        "nx.draw_networkx_nodes(G, pos, partition.keys(), node_size=1, cmap=cmap, node_color=list(partition.values()))\n",
        "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}